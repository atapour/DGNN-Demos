{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DrpK6lIWrhi"
      },
      "source": [
        "# Diffusion Model Implementation with U-Net on MNIST\n",
        "\n",
        "---\n",
        "\n",
        "## Author : Amir Atapour-Abarghouei, amir.atapour-abarghouei@durham.ac.uk\n",
        "\n",
        "This notebook demonstrates the implementation of a diffusion model using a U-Net architecture on the MNIST dataset.\n",
        "\n",
        "Copyright (c) 2024 Amir Atapour-Abarghouei, UK.\n",
        "\n",
        "License : GNU General Public License Version 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-exrFDujXlUG"
      },
      "source": [
        "We are going to implement a very simple GAN. Let's start by importing what we need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7Xgr3ZNXmQx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from einops import rearrange\n",
        "from torchvision import transforms\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f\"Device is {device}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZr-PApBcN4Y"
      },
      "source": [
        "We should now line up the dataset we are going to use. We will be MNIST.\n",
        "\n",
        "We'll load and preprocess the MNIST dataset, which contains 28x28 grayscale images of handwritten digits. We'll resize these images to 32x32 and convert them to 3 channels to match the input requirements of our U-Net model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bGhK9wmXsA_"
      },
      "outputs": [],
      "source": [
        "# MNIST dataloader\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST(\"./data\", train=True, download=True,\n",
        "                               transform=transforms.Compose([\n",
        "                                   transforms.Resize((32, 32)),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Lambda(lambda x: x.repeat(3,1,1)),  # Convert 1-channel grayscale to 3 channels\n",
        "                                   transforms.Normalize((0.5,), (0.5,))\n",
        "                               ])), batch_size=16, shuffle=True)\n",
        "\n",
        "# Check data loading\n",
        "x, _ = next(iter(train_loader))\n",
        "plt.imshow(rearrange(x[0], 'c h w -> h w c').cpu() * 0.5 + 0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6AZQ9Kq_1hj"
      },
      "source": [
        "Now is time to define our model, a U-Net with DDPM.\n",
        "\n",
        "We’ll define a U-Net model to serve as the backbone for our diffusion process. Note that this model, along with the rest of this implementation, is extremely simplified for educational purposes and shoud not be relied upon for any real applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbTxY01eY0Aq"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, out_class=3):\n",
        "        super().__init__()\n",
        "        self.dconv_down1 = self.conv_block(72)\n",
        "        self.dconv_down2 = self.conv_block(96)\n",
        "        self.dconv_down3 = self.conv_block(128)\n",
        "        self.dconv_down4 = self.conv_block(196)\n",
        "        self.dconv_down5 = self.conv_block(256)\n",
        "        self.bottleneck  = nn.LazyConv2d(256, 3,1,1, bias=False)\n",
        "        self.dconv_up4 = self.conv_block(256, up=True)\n",
        "        self.dconv_up3 = self.conv_block(196, up=True)\n",
        "        self.dconv_up2 = self.conv_block(128, up=True)\n",
        "        self.dconv_up1 = self.conv_block(96, up=True)\n",
        "        self.conv_last = nn.LazyConv2d(out_class, 1)\n",
        "\n",
        "    def conv_block(self, out_channels, up=False):\n",
        "        ConvType = nn.LazyConvTranspose2d if up else nn.LazyConv2d\n",
        "        return nn.Sequential(\n",
        "            ConvType(out_channels, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU())\n",
        "\n",
        "    def forward(self, x, c):\n",
        "        start = x\n",
        "        conv1 = self.dconv_down1(x)     # skip-connection 1\n",
        "        conv2 = self.dconv_down2(conv1) # skip-connection 2\n",
        "        conv3 = self.dconv_down3(conv2) # skip-connection 3\n",
        "        conv4 = self.dconv_down4(conv3) # skip-connection 4\n",
        "\n",
        "        # simple inject of the conditionals into the network\n",
        "        ch = F.one_hot(c, num_classes=10).float().to(device).view(-1,10,1,1)\n",
        "\n",
        "        x = self.bottleneck(conv4)\n",
        "        x = torch.cat([x, conv4, ch.repeat(1,1,x.size(2),x.size(3))], dim=1) # injection 1\n",
        "        x = self.dconv_up4(x)\n",
        "        x = torch.cat([x, conv3, ch.repeat(1,1,x.size(2),x.size(3))], dim=1) # injection 2\n",
        "        x = self.dconv_up3(x)\n",
        "        x = torch.cat([x, conv2], dim=1)\n",
        "        x = self.dconv_up2(x)\n",
        "        x = torch.cat([x, conv1], dim=1)\n",
        "        x = self.dconv_up1(x)\n",
        "        x = torch.cat([x, start], dim=1)\n",
        "        return self.conv_last(x)\n",
        "\n",
        "print(f\"The architecture has been created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5UnQLwJZW6O"
      },
      "source": [
        "Now, we will define the DDPM model using the U-Net architecture and set up the training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVqAtMBuw8LW"
      },
      "outputs": [],
      "source": [
        "class DDPM(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super(DDPM, self).__init__()\n",
        "        self.net = UNet()\n",
        "\n",
        "    # Algorithm 1 in DDPM paper with conditionals\n",
        "    def forward(self, x, c):\n",
        "        _ts = torch.randint(1, T+1, (x.shape[0],)).to(x.device)\n",
        "        eps = torch.randn_like(x)\n",
        "        x_t = (sqrtab[_ts] * x + sqrtmab[_ts] * eps)\n",
        "        return F.mse_loss(eps, self.net(x_t, c))\n",
        "\n",
        "    # Algorithm 2 in DDPM paper with torch.arange(n_sample) conditionals\n",
        "    def sample(self, n_sample, size):\n",
        "        x_i = torch.randn(n_sample, *size).to(device)\n",
        "        for i in range(T, 0, -1):\n",
        "            z = torch.randn(n_sample, *size).to(device) if i > 1 else 0\n",
        "            eps = self.net(x_i, torch.arange(n_sample))\n",
        "            x_i = (oneover_sqrta[i] * (x_i - eps * mab_over_sqrtmab_inv[i]) + sigma_t[i] * z )\n",
        "        return x_i\n",
        "\n",
        "    print(f\"The DDPM model has been created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt8tSeQcy_jZ"
      },
      "source": [
        "Here’s the training loop, where we optimise the model to predict the noise added to the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pou-TRizzZXP"
      },
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "T = 400\n",
        "beta1 = 1e-4\n",
        "beta2 = 0.02\n",
        "beta_t = (beta2 - beta1) * torch.arange(0, T + 1, dtype=torch.float32, device=device) / T + beta1\n",
        "alpha_t = 1 - beta_t\n",
        "log_alpha_t = torch.log(alpha_t)\n",
        "alphabar_t = torch.cumsum(log_alpha_t, dim=0).exp()\n",
        "sqrtab = torch.sqrt(alphabar_t).view(-1,1,1,1)\n",
        "sqrtmab = torch.sqrt(1 - alphabar_t).view(-1,1,1,1)\n",
        "oneover_sqrta = 1 / torch.sqrt(alpha_t)\n",
        "mab_over_sqrtmab_inv = (1 - alpha_t) / sqrtmab.squeeze()\n",
        "sigma_t = torch.sqrt(beta_t)\n",
        "\n",
        "ddpm = DDPM().to(device)\n",
        "optim = torch.optim.Adam(ddpm.parameters(), lr=1e-4)\n",
        "\n",
        "# Training loop\n",
        "for step in range(20000):\n",
        "    x, c = next(iter(train_loader))\n",
        "    x, c = x.to(device), c.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    loss = ddpm(x, c)\n",
        "\n",
        "    # Backward pass\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    # Print progress\n",
        "    if step % 500 == 0:\n",
        "        print(f\"Step {step}, Loss: {loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will generate new images using the trained diffusion model by sampling from the reverse process."
      ],
      "metadata": {
        "id": "baDzpzyZtA08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampling new images\n",
        "ddpm.eval()\n",
        "with torch.no_grad():\n",
        "    xh = ddpm.sample(10, (3, 32, 32))\n",
        "    img_grid = rearrange(xh*0.5+0.5, '(b1 b2) c h w -> (b1 h) (b2 w) c', b1=1)\n",
        "    plt.imshow((img_grid.cpu()*255).int().numpy())\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "QkFPhqhdtDJV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit ('3.9.13')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "fff836058c255167b80f2d77a2226e7e00ff1ecf6518b7f3cd25e9b70384f747"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}